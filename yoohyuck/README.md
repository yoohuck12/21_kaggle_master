Kaggle Study 계획표

C3 인 'Natural Language Processing with Disaster Tweets' 시작 + Starter 병행

- [1주] EDA (Competition 이해 및 insight 얻기)
    - Starter - [Intro to ML](https://www.kaggle.com/learn/intro-to-machine-learning), Intermediate ML, Data Visualization
    - '[Twitter sentiment Extraction-Analysis,EDA and Model](https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model)' '[EDA and models](https://www.kaggle.com/artgor/eda-and-models)' 따라해보기
- [2주] Baseline 모델 (framework 고려) 리뷰 및 학습
    - Data Cleaning, Feature Engineering, ML Explainability
    - 모델 2개 이상 보기 (BERT 외에도.)
- [3주] 최고 성능 모델 (ensemble 등) 리뷰 및 적용
    - 다음으로 할 Closed Competition 을 정하기.
    - 적용가능한 NLP 논문을 1개정도 읽어보기

주제 선정 2개 더 하기. (NLP 관련해서 정리하면서 보자.)

- COVID - [https://www.kaggle.com/bcgvaccine/hackathon](https://www.kaggle.com/bcgvaccine/hackathon), [https://www.kaggle.com/thesumitbanik/covid-fake-news-dataset](https://www.kaggle.com/thesumitbanik/covid-fake-news-dataset)

좋은 노트북도 한주에 한개는 보자!

1. [Approaching (Almost) Any NLP Problem on Kaggle](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle)
2. [Credit Fraud || Dealing with Imbalanced Datasets](https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets)
3. [EDA and models](https://www.kaggle.com/artgor/eda-and-models)
4. [Twitter sentiment Extraction-Analysis,EDA and Model](https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model)
5. How to not overfit?
6. Dealing with very small datasets




What's Done
[2021.01.18]
  - Intro to Machine Learning: How to Submit using saved version, How to
  preprocess, build model using RandomForest, Data split with train_test_split.
    - Submit with RandomForestRegressor.
  - Start to see Mr_KnowNothing's [Twitter sentiment Extaction-Analysis,EDA and Model](https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model)
